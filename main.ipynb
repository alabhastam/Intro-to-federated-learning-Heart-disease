{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":477177,"sourceType":"datasetVersion","datasetId":216167}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T13:30:32.294593Z","iopub.execute_input":"2025-09-17T13:30:32.294897Z","iopub.status.idle":"2025-09-17T13:30:32.902086Z","shell.execute_reply.started":"2025-09-17T13:30:32.294870Z","shell.execute_reply":"2025-09-17T13:30:32.901215Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/heart-disease-dataset/heart.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"<div style=\"background-color:green;color:#EAEAEA;font-family:Arial,Helvetica,sans-serif;padding:20px;border-radius:8px;line-height:1.6\">\n  <h1 style=\"color:#4CAF50;text-align:center;\">üìö Introduction to Federated Learning</h1>\n  \n  <h2 style=\"color:#FFD700;\">1. What is Federated Learning?</h2>\n  <p>\n    Federated Learning (FL) is a <b>decentralized machine learning approach</b> where multiple devices or organizations collaboratively train a model without sharing their raw data. Instead of sending data to a central server, each participant trains a local model and only shares model updates.\n  </p>\n  <p>\n    Think of it as many chefs cooking in their own kitchens, but sharing only their <i>recipe improvements</i> ‚Äî not the secret ingredients.\n  </p>\n  \n  <h2 style=\"color:#FFD700;\">2. Why is Federated Learning Important?</h2>\n  <ul>\n    <li>‚úÖ <b>Privacy Preservation:</b> Sensitive data never leaves the local device.</li>\n    <li>‚úÖ <b>Reduced Data Transfer:</b> Only model parameters/gradients are exchanged.</li>\n    <li>‚úÖ <b>Regulatory Compliance:</b> Helps meet GDPR, HIPAA, and similar regulations.</li>\n    <li>‚úÖ <b>Edge Computing:</b> Utilizes data and compute resources at the source.</li>\n  </ul>\n  \n  <h2 style=\"color:#FFD700;\">3. How Does It Work?</h2>\n  <ol>\n    <li>üì§ <b>Server sends initial model</b> to all participants.</li>\n    <li>üñ•Ô∏è <b>Local training</b> happens on each participant's private data.</li>\n    <li>üì• <b>Local model updates</b> are sent back to the server.</li>\n    <li>üîÑ <b>Aggregation</b> (e.g., FedAvg algorithm) combines updates into a global model.</li>\n    <li>üîÅ Repeat until the model converges.</li>\n  </ol>\n  \n  <h2 style=\"color:#FFD700;\">4. Real-World Example</h2>\n  <p>\n    Google‚Äôs <b>Gboard keyboard</b> uses Federated Learning to improve text prediction:\n    your typed messages stay on your device, while only the learned model changes are sent\n    to improve the shared model.\n  </p>\n  \n  <h2 style=\"color:#FFD700;\">5. Key Challenges</h2>\n  <ul>\n    <li>‚ö†Ô∏è <b>Non-IID Data:</b> Data distributions differ across participants.</li>\n    <li>‚ö†Ô∏è <b>Network Reliability:</b> Communication delays affect training speed.</li>\n    <li>‚ö†Ô∏è <b>Security:</b> Model updates can still leak sensitive patterns.</li>\n    <li>‚ö†Ô∏è <b>Client Coordination:</b> Handling dropped or slow clients is tricky.</li>\n  </ul>\n  \n  <h2 style=\"color:#FFD700;\">6. Common Techniques</h2>\n  <ul>\n    <li>üîπ <b>FedAvg:</b> Weighted average of client models.</li>\n    <li>üîπ <b>Secure Aggregation:</b> Protects updates during transfer.</li>\n    <li>üîπ <b>Differential Privacy:</b> Adds noise to updates for privacy.</li>\n    <li>üîπ <b>Model Personalization:</b> Tailors global models to local needs.</li>\n  </ul>\n</div>\n","metadata":{}}]}