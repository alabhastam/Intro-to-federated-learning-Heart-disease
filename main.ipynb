{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aabdollahii/intro-to-federated-learning-heart-disease?scriptVersionId=262845502\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"1be6be69","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-09-19T17:44:18.461008Z","iopub.status.busy":"2025-09-19T17:44:18.460685Z","iopub.status.idle":"2025-09-19T17:44:20.307328Z","shell.execute_reply":"2025-09-19T17:44:20.306418Z"},"papermill":{"duration":1.852755,"end_time":"2025-09-19T17:44:20.308734","exception":false,"start_time":"2025-09-19T17:44:18.455979","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/heart-disease-dataset/heart.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","id":"68c9da97","metadata":{"papermill":{"duration":0.002374,"end_time":"2025-09-19T17:44:20.314435","exception":false,"start_time":"2025-09-19T17:44:20.312061","status":"completed"},"tags":[]},"source":["<div style=\"background-color:green;color:#EAEAEA;font-family:Arial,Helvetica,sans-serif;padding:20px;border-radius:8px;line-height:1.6\">\n","  <h1 style=\"color:#4CAF50;text-align:center;\">📚 Introduction to Federated Learning</h1>\n","  \n","  <h2 style=\"color:#FFD700;\">1. What is Federated Learning?</h2>\n","  <p>\n","    Federated Learning (FL) is a <b>decentralized machine learning approach</b> where multiple devices or organizations collaboratively train a model without sharing their raw data. Instead of sending data to a central server, each participant trains a local model and only shares model updates.\n","  </p>\n","  <p>\n","    Think of it as many chefs cooking in their own kitchens, but sharing only their <i>recipe improvements</i> — not the secret ingredients.\n","  </p>\n","  \n","  <h2 style=\"color:#FFD700;\">2. Why is Federated Learning Important?</h2>\n","  <ul>\n","    <li>✅ <b>Privacy Preservation:</b> Sensitive data never leaves the local device.</li>\n","    <li>✅ <b>Reduced Data Transfer:</b> Only model parameters/gradients are exchanged.</li>\n","    <li>✅ <b>Regulatory Compliance:</b> Helps meet GDPR, HIPAA, and similar regulations.</li>\n","    <li>✅ <b>Edge Computing:</b> Utilizes data and compute resources at the source.</li>\n","  </ul>\n","  \n","  <h2 style=\"color:#FFD700;\">3. How Does It Work?</h2>\n","  <ol>\n","    <li>📤 <b>Server sends initial model</b> to all participants.</li>\n","    <li>🖥️ <b>Local training</b> happens on each participant's private data.</li>\n","    <li>📥 <b>Local model updates</b> are sent back to the server.</li>\n","    <li>🔄 <b>Aggregation</b> (e.g., FedAvg algorithm) combines updates into a global model.</li>\n","    <li>🔁 Repeat until the model converges.</li>\n","  </ol>\n","  \n","  <h2 style=\"color:#FFD700;\">4. Real-World Example</h2>\n","  <p>\n","    Google’s <b>Gboard keyboard</b> uses Federated Learning to improve text prediction:\n","    your typed messages stay on your device, while only the learned model changes are sent\n","    to improve the shared model.\n","  </p>\n","  \n","  <h2 style=\"color:#FFD700;\">5. Key Challenges</h2>\n","  <ul>\n","    <li>⚠️ <b>Non-IID Data:</b> Data distributions differ across participants.</li>\n","    <li>⚠️ <b>Network Reliability:</b> Communication delays affect training speed.</li>\n","    <li>⚠️ <b>Security:</b> Model updates can still leak sensitive patterns.</li>\n","    <li>⚠️ <b>Client Coordination:</b> Handling dropped or slow clients is tricky.</li>\n","  </ul>\n","  \n","  <h2 style=\"color:#FFD700;\">6. Common Techniques</h2>\n","  <ul>\n","    <li>🔹 <b>FedAvg:</b> Weighted average of client models.</li>\n","    <li>🔹 <b>Secure Aggregation:</b> Protects updates during transfer.</li>\n","    <li>🔹 <b>Differential Privacy:</b> Adds noise to updates for privacy.</li>\n","    <li>🔹 <b>Model Personalization:</b> Tailors global models to local needs.</li>\n","  </ul>\n","</div>\n"]},{"cell_type":"markdown","id":"d6ecc15c","metadata":{"papermill":{"duration":0.002334,"end_time":"2025-09-19T17:44:20.319314","exception":false,"start_time":"2025-09-19T17:44:20.31698","status":"completed"},"tags":[]},"source":["<div style=\"background-color:green;color:pur;font-family:Arial,Helvetica,sans-serif;padding:20px;border-radius:8px;line-height:1.6\">\n","  <h1 style=\"color:#FF4C4C;text-align:center;\"> Step 1: Loading and Understanding the Heart Disease Dataset</h1>\n","  \n","  <p>\n","    In this step, we load the <b>Heart Disease Dataset</b> directly from our Kaggle input folder and take a first look at its structure.\n","    This dataset contains multiple health-related attributes such as <i>age, cholesterol, blood pressure, maximum heart rate</i>,\n","    and a <b>target</b> column indicating the presence or absence of heart disease.\n","  </p>\n","  \n","  <h2 style=\"color:#FFD700;\">📋 Dataset Overview</h2>\n","  <ul>\n","    <li><b>File size:</b> ~200 KB — lightning fast to load.</li>\n","    <li><b>Rows:</b> Each row represents a patient's record.</li>\n","    <li><b>Columns:</b> Include both numerical (e.g., age, cholesterol) and categorical (e.g., sex, chest pain type) features.</li>\n","    <li><b>Target variable:</b> <code>target</code> — <b>1</b> means heart disease present, <b>0</b> means absent.</li>\n","  </ul>\n","  \n","  <h2 style=\"color:#FFD700;\">🔍 Why This Step Matters</h2>\n","  <p>\n","    Before applying any machine learning — especially Federated Learning —\n","    we need to:\n","    <ul>\n","      <li>✅ Verify we can load the dataset properly.</li>\n","      <li>✅ Understand basic column meanings and data types.</li>\n","      <li>✅ Check for missing values and simple statistics.</li>\n","    </ul>\n","  </p>\n","  \n","  <p><b>Next:</b> We'll explore the dataset with Pandas to confirm its structure and prepare it for federated splitting.</p>\n","</div>\n"]},{"cell_type":"code","execution_count":2,"id":"b0893fe4","metadata":{"execution":{"iopub.execute_input":"2025-09-19T17:44:20.325624Z","iopub.status.busy":"2025-09-19T17:44:20.325162Z","iopub.status.idle":"2025-09-19T17:44:20.429214Z","shell.execute_reply":"2025-09-19T17:44:20.42833Z"},"papermill":{"duration":0.109051,"end_time":"2025-09-19T17:44:20.430821","exception":false,"start_time":"2025-09-19T17:44:20.32177","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset shape: (1025, 14)\n","\n","First 5 rows:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>cp</th>\n","      <th>trestbps</th>\n","      <th>chol</th>\n","      <th>fbs</th>\n","      <th>restecg</th>\n","      <th>thalach</th>\n","      <th>exang</th>\n","      <th>oldpeak</th>\n","      <th>slope</th>\n","      <th>ca</th>\n","      <th>thal</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>52</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>125</td>\n","      <td>212</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>168</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>53</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>140</td>\n","      <td>203</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>155</td>\n","      <td>1</td>\n","      <td>3.1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>145</td>\n","      <td>174</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>125</td>\n","      <td>1</td>\n","      <td>2.6</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>61</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>148</td>\n","      <td>203</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>161</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>62</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>138</td>\n","      <td>294</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>106</td>\n","      <td>0</td>\n","      <td>1.9</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n","0   52    1   0       125   212    0        1      168      0      1.0      2   \n","1   53    1   0       140   203    1        0      155      1      3.1      0   \n","2   70    1   0       145   174    0        1      125      1      2.6      0   \n","3   61    1   0       148   203    0        1      161      0      0.0      2   \n","4   62    0   0       138   294    1        1      106      0      1.9      1   \n","\n","   ca  thal  target  \n","0   2     3       0  \n","1   0     3       0  \n","2   0     3       0  \n","3   1     3       0  \n","4   3     2       0  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Dataset Info:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1025 entries, 0 to 1024\n","Data columns (total 14 columns):\n"," #   Column    Non-Null Count  Dtype  \n","---  ------    --------------  -----  \n"," 0   age       1025 non-null   int64  \n"," 1   sex       1025 non-null   int64  \n"," 2   cp        1025 non-null   int64  \n"," 3   trestbps  1025 non-null   int64  \n"," 4   chol      1025 non-null   int64  \n"," 5   fbs       1025 non-null   int64  \n"," 6   restecg   1025 non-null   int64  \n"," 7   thalach   1025 non-null   int64  \n"," 8   exang     1025 non-null   int64  \n"," 9   oldpeak   1025 non-null   float64\n"," 10  slope     1025 non-null   int64  \n"," 11  ca        1025 non-null   int64  \n"," 12  thal      1025 non-null   int64  \n"," 13  target    1025 non-null   int64  \n","dtypes: float64(1), int64(13)\n","memory usage: 112.2 KB\n","None\n","\n","Summary Statistics:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>cp</th>\n","      <th>trestbps</th>\n","      <th>chol</th>\n","      <th>fbs</th>\n","      <th>restecg</th>\n","      <th>thalach</th>\n","      <th>exang</th>\n","      <th>oldpeak</th>\n","      <th>slope</th>\n","      <th>ca</th>\n","      <th>thal</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.00000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","      <td>1025.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>54.434146</td>\n","      <td>0.695610</td>\n","      <td>0.942439</td>\n","      <td>131.611707</td>\n","      <td>246.00000</td>\n","      <td>0.149268</td>\n","      <td>0.529756</td>\n","      <td>149.114146</td>\n","      <td>0.336585</td>\n","      <td>1.071512</td>\n","      <td>1.385366</td>\n","      <td>0.754146</td>\n","      <td>2.323902</td>\n","      <td>0.513171</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>9.072290</td>\n","      <td>0.460373</td>\n","      <td>1.029641</td>\n","      <td>17.516718</td>\n","      <td>51.59251</td>\n","      <td>0.356527</td>\n","      <td>0.527878</td>\n","      <td>23.005724</td>\n","      <td>0.472772</td>\n","      <td>1.175053</td>\n","      <td>0.617755</td>\n","      <td>1.030798</td>\n","      <td>0.620660</td>\n","      <td>0.500070</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>29.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>94.000000</td>\n","      <td>126.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>71.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>48.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>120.000000</td>\n","      <td>211.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>132.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>56.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>130.000000</td>\n","      <td>240.00000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>152.000000</td>\n","      <td>0.000000</td>\n","      <td>0.800000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>61.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>140.000000</td>\n","      <td>275.00000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>166.000000</td>\n","      <td>1.000000</td>\n","      <td>1.800000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>77.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>200.000000</td>\n","      <td>564.00000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>202.000000</td>\n","      <td>1.000000</td>\n","      <td>6.200000</td>\n","      <td>2.000000</td>\n","      <td>4.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               age          sex           cp     trestbps        chol  \\\n","count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000   \n","mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n","std       9.072290     0.460373     1.029641    17.516718    51.59251   \n","min      29.000000     0.000000     0.000000    94.000000   126.00000   \n","25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n","50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n","75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n","max      77.000000     1.000000     3.000000   200.000000   564.00000   \n","\n","               fbs      restecg      thalach        exang      oldpeak  \\\n","count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n","mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n","std       0.356527     0.527878    23.005724     0.472772     1.175053   \n","min       0.000000     0.000000    71.000000     0.000000     0.000000   \n","25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n","50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n","75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n","max       1.000000     2.000000   202.000000     1.000000     6.200000   \n","\n","             slope           ca         thal       target  \n","count  1025.000000  1025.000000  1025.000000  1025.000000  \n","mean      1.385366     0.754146     2.323902     0.513171  \n","std       0.617755     1.030798     0.620660     0.500070  \n","min       0.000000     0.000000     0.000000     0.000000  \n","25%       1.000000     0.000000     2.000000     0.000000  \n","50%       1.000000     0.000000     2.000000     1.000000  \n","75%       2.000000     1.000000     3.000000     1.000000  \n","max       2.000000     4.000000     3.000000     1.000000  "]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Missing values per column:\n","age         0\n","sex         0\n","cp          0\n","trestbps    0\n","chol        0\n","fbs         0\n","restecg     0\n","thalach     0\n","exang       0\n","oldpeak     0\n","slope       0\n","ca          0\n","thal        0\n","target      0\n","dtype: int64\n"]}],"source":["import pandas as pd\n","\n","# Load dataset from Kaggle input folder\n","df = pd.read_csv(\"/kaggle/input/heart-disease-dataset/heart.csv\")\n","\n","# Basic info\n","print(\"Dataset shape:\", df.shape)\n","print(\"\\nFirst 5 rows:\")\n","display(df.head())\n","\n","# Column info\n","print(\"\\nDataset Info:\")\n","print(df.info())\n","\n","# Summary statistics\n","print(\"\\nSummary Statistics:\")\n","display(df.describe())\n","\n","# Check missing values\n","print(\"\\nMissing values per column:\")\n","print(df.isnull().sum())\n"]},{"cell_type":"markdown","id":"ddf362dd","metadata":{"papermill":{"duration":0.003074,"end_time":"2025-09-19T17:44:20.437786","exception":false,"start_time":"2025-09-19T17:44:20.434712","status":"completed"},"tags":[]},"source":["<div style=\"background-color:green;color:#EAEAEA;font-family:Arial,Helvetica,sans-serif;padding:20px;border-radius:8px;line-height:1.6\">\n","  <h1 style=\"color:#FF4C4C;text-align:center;\">💓 Step 1 — Dataset Understanding Results</h1>\n","  \n","  <h2 style=\"color:#FFD700;\">📦 Dataset Shape & Structure</h2>\n","  <ul>\n","    <li><b>Rows:</b> 1,025 patient records.</li>\n","    <li><b>Columns:</b> 14 features including the <code>target</code> label.</li>\n","    <li>All features are <b>numeric</b> — 13 integers & 1 float (<code>oldpeak</code>).</li>\n","    <li><b>No missing values</b> — dataset is clean and ready for modeling.</li>\n","  </ul>\n","  \n","  <h2 style=\"color:#FFD700;\">🔍 Feature Insights</h2>\n","  <ul>\n","    <li><b>Age:</b> Ranges from 29 to 77 years (mean ≈ 54).</li>\n","    <li><b>Sex:</b> Binary (0 = female, 1 = male), majority are male (~70%).</li>\n","    <li><b>Chest Pain Type (<code>cp</code>):</b> Values from 0 to 3, representing categories.</li>\n","    <li><b>Resting Blood Pressure (<code>trestbps</code>):</b> Average ≈ 132 mm Hg.</li>\n","    <li><b>Cholesterol (<code>chol</code>):</b> Average ≈ 246 mg/dL, some unusually high values (max 564).</li>\n","    <li><b>Max Heart Rate Achieved (<code>thalach</code>):</b> Ranges from 71 to 202 bpm, mean ≈ 149 bpm.</li>\n","    <li><b>Depression (<code>oldpeak</code>):</b> Continuous, ranges 0 → 6.2.</li>\n","  </ul>\n","  \n","  <h2 style=\"color:#FFD700;\">🎯 Target Variable</h2>\n","  <ul>\n","    <li><code>target</code> = 1 → Heart disease present.</li>\n","    <li><code>target</code> = 0 → No heart disease.</li>\n","    <li>Balanced enough for binary classification (~51% positive cases).</li>\n","  </ul>\n","  \n","  <h2 style=\"color:#FFD700;\">💡 Key Observations</h2>\n","  <ul>\n","    <li>✅ Completely clean — no missing data, ready for immediate use.</li>\n","    <li>✅ Mix of categorical-encoded and continuous numeric features.</li>\n","    <li>⚠️ Some features (e.g., cholesterol) have extreme outliers that may influence training.</li>\n","    <li>🌐 Perfect for simulating <b>federated learning</b> via partitioning patient records into multiple hospitals/clients.</li>\n","  </ul>\n","</div>\n"]},{"cell_type":"markdown","id":"db512550","metadata":{"papermill":{"duration":0.002984,"end_time":"2025-09-19T17:44:20.44402","exception":false,"start_time":"2025-09-19T17:44:20.441036","status":"completed"},"tags":[]},"source":["<div style=\"background-color:green;color:#EAEAEA;font-family:Arial,Helvetica,sans-serif;padding:20px;border-radius:8px;line-height:1.6\">\n","  <h1 style=\"color:#FF4C4C;text-align:center;\">🏥 Step 2 — Simulating Federated Clients</h1>\n","  \n","  <p>\n","    To mimic how Federated Learning works in the real world, we split our heart disease dataset into multiple <b>clients</b>.\n","    You can think of each client as a separate hospital or clinic that has its own patient records.\n","    This lets us train a shared global model <i>without sharing raw data</i>.\n","  </p>\n","  \n","  <h2 style=\"color:#FFD700;\">📌 Types of Splits</h2>\n","  <ul>\n","    <li><b>IID (Independent & Identically Distributed):</b> Each client gets a random and balanced mix of heart disease and non-disease cases.</li>\n","    <li><b>Non-IID:</b> Each client has a biased patient set — for example, some may have mostly patients with heart disease, while others have mostly healthy patients. This simulates real-world hospital specialization and demographics.</li>\n","  </ul>\n","  \n","  <h2 style=\"color:#FFD700;\">💡 Why Simulate IID & Non-IID?</h2>\n","  <ul>\n","    <li>✅ Understanding how data distribution affects model performance.</li>\n","    <li>✅ Demonstrating the challenges of heterogeneous data in Federated Learning.</li>\n","    <li>✅ Showing why techniques like <b>FedAvg</b> need to handle imbalance.</li>\n","  </ul>\n","  \n","  <p>\n","    In the following code, we will:\n","    <ol>\n","      <li>Define the number of simulated clients.</li>\n","      <li>Create an IID split of the dataset.</li>\n","      <li>Create a Non-IID split of the dataset.</li>\n","      <li>Store them for use in local client training.</li>\n","    </ol>\n","  </p>\n","</div>\n"]},{"cell_type":"code","execution_count":3,"id":"c5b194a7","metadata":{"execution":{"iopub.execute_input":"2025-09-19T17:44:20.451843Z","iopub.status.busy":"2025-09-19T17:44:20.451532Z","iopub.status.idle":"2025-09-19T17:44:20.550858Z","shell.execute_reply":"2025-09-19T17:44:20.549818Z"},"papermill":{"duration":0.105139,"end_time":"2025-09-19T17:44:20.552337","exception":false,"start_time":"2025-09-19T17:44:20.447198","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["IID client sizes:\n"," Client 1: 205 samples\n"," Client 2: 205 samples\n"," Client 3: 205 samples\n"," Client 4: 205 samples\n"," Client 5: 205 samples\n","\n","Non-IID client sizes:\n"," Client 1: 132 samples, Class balance:\n","target\n","0    100\n","1     32\n","Name: count, dtype: int64\n"," Client 2: 132 samples, Class balance:\n","target\n","0    100\n","1     32\n","Name: count, dtype: int64\n"," Client 3: 135 samples, Class balance:\n","target\n","1    105\n","0     30\n","Name: count, dtype: int64\n"," Client 4: 135 samples, Class balance:\n","target\n","1    105\n","0     30\n","Name: count, dtype: int64\n"," Client 5: 135 samples, Class balance:\n","target\n","1    105\n","0     30\n","Name: count, dtype: int64\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n","  return bound(*args, **kwds)\n"]}],"source":["import numpy as np\n","\n","# Number of simulated clients\n","NUM_CLIENTS = 5\n","\n","# Function for IID split\n","def iid_split(df, num_clients):\n","    shuffled_df = df.sample(frac=1).reset_index(drop=True)\n","    return np.array_split(shuffled_df, num_clients)\n","\n","# Function for Non-IID split based on 'target'\n","def non_iid_split(df, num_clients):\n","    df_class0 = df[df['target'] == 0].sample(frac=1).reset_index(drop=True)\n","    df_class1 = df[df['target'] == 1].sample(frac=1).reset_index(drop=True)\n","    \n","    # Split each class separately\n","    class0_splits = np.array_split(df_class0, num_clients)\n","    class1_splits = np.array_split(df_class1, num_clients)\n","    \n","    # Assign biased portions: first half more class0, second half more class1\n","    clients = []\n","    for i in range(num_clients):\n","        if i < num_clients // 2:\n","            client_data = pd.concat([class0_splits[i], class1_splits[i].sample(frac=0.3)])\n","        else:\n","            client_data = pd.concat([class1_splits[i], class0_splits[i].sample(frac=0.3)])\n","        clients.append(client_data.sample(frac=1).reset_index(drop=True))\n","    return clients\n","\n","# Create splits\n","iid_clients = iid_split(df, NUM_CLIENTS)\n","non_iid_clients = non_iid_split(df, NUM_CLIENTS)\n","\n","# Print sample sizes\n","print(\"IID client sizes:\")\n","for i, client in enumerate(iid_clients):\n","    print(f\" Client {i+1}: {len(client)} samples\")\n","\n","print(\"\\nNon-IID client sizes:\")\n","for i, client in enumerate(non_iid_clients):\n","    print(f\" Client {i+1}: {len(client)} samples, Class balance:\\n{client['target'].value_counts()}\")\n"]},{"cell_type":"markdown","id":"34e965de","metadata":{"papermill":{"duration":0.003251,"end_time":"2025-09-19T17:44:20.559246","exception":false,"start_time":"2025-09-19T17:44:20.555995","status":"completed"},"tags":[]},"source":["<div style=\"background-color:green;color:#EAEAEA;font-family:Arial,Helvetica,sans-serif;padding:20px;border-radius:8px;line-height:1.6\">\n","  <h1 style=\"color:#FF4C4C;text-align:center;\">🏥 Step 2 — Client Split Summary</h1>\n","  \n","  <h2 style=\"color:#FFD700;\">📊 IID (Independent & Identically Distributed) Clients</h2>\n","  <p>\n","    In the IID split, each of our <b>5 simulated clients</b> received the same number of samples,\n","    with a balanced distribution of both positive and negative heart disease cases.\n","  </p>\n","  <ul>\n","    <li>Client 1 → 205 samples</li>\n","    <li>Client 2 → 205 samples</li>\n","    <li>Client 3 → 205 samples</li>\n","    <li>Client 4 → 205 samples</li>\n","    <li>Client 5 → 205 samples</li>\n","  </ul>\n","  \n","  <h2 style=\"color:#FFD700;\">📊 Non-IID (Non-Identically Distributed) Clients</h2>\n","  <p>\n","    In the Non-IID split, class distributions are intentionally skewed to mimic real-world hospital bias.\n","    Some clients mostly treat healthy patients, others see more heart disease cases.\n","  </p>\n","  \n","  <ul>\n","    <li>Client 1 → 132 samples (100 no-disease, 32 disease)</li>\n","    <li>Client 2 → 132 samples (100 no-disease, 32 disease)</li>\n","    <li>Client 3 → 135 samples (105 disease, 30 no-disease)</li>\n","    <li>Client 4 → 135 samples (105 disease, 30 no-disease)</li>\n","    <li>Client 5 → 135 samples (105 disease, 30 no-disease)</li>\n","  </ul>\n","  \n","  <h2 style=\"color:#FFD700;\">💡 Key Takeaways</h2>\n","  <ul>\n","    <li>✅ IID data ensures uniform learning across clients.</li>\n","    <li>⚠️ Non-IID data adds challenge: models trained in isolation may bias towards local patterns.</li>\n","    <li>🌐 Federated averaging (FedAvg) helps bring these local models together into a single global model.</li>\n","  </ul>\n","</div>\n"]},{"cell_type":"markdown","id":"cccf6574","metadata":{"papermill":{"duration":0.003039,"end_time":"2025-09-19T17:44:20.565674","exception":false,"start_time":"2025-09-19T17:44:20.562635","status":"completed"},"tags":[]},"source":["<div style=\"background-color:green;color:#EAEAEA;font-family:Arial,Helvetica,sans-serif;padding:20px;border-radius:8px;line-height:1.6\">\n","  <h1 style=\"color:#FF4C4C;text-align:center;\">⚙️ Step 3 — Federated Model Training</h1>\n","  \n","  <p>\n","    Now that we have simulated our federated clients, it's time to train models in a distributed fashion.\n","    Each client trains on <b>their own local dataset</b> (without sharing their raw data), and then sends the trained model's parameters to a central server.\n","  </p>\n","  \n","  <h2 style=\"color:#FFD700;\">📌 Federated Averaging (FedAvg)</h2>\n","  <p>\n","    FedAvg is the most well-known algorithm in Federated Learning. It works as follows:\n","  </p>\n","  <ol>\n","    <li>A central server sends a shared model to each client.</li>\n","    <li>Each client trains the model locally for a set number of epochs.</li>\n","    <li>Clients send back only the <i>model weights</i> (not the data).</li>\n","    <li>The server <b>averages</b> these weights to update the global model.</li>\n","  </ol>\n","  \n","  <h2 style=\"color:#FFD700;\">💡 Why This Matters</h2>\n","  <ul>\n","    <li>✅ Keeps data private — important in healthcare applications.</li>\n","    <li>✅ Reduces central server storage needs.</li>\n","    <li>⚠️ Still sensitive to Non-IID challenges, which can slow convergence.</li>\n","  </ul>\n","  \n","  <p>\n","    In the following code, we will implement a simple <b>FedAvg pipeline</b> using <b>Logistic Regression</b> as our base model.\n","    This will help us focus on the FL process without complex model tuning.\n","  </p>\n","</div>\n"]},{"cell_type":"code","execution_count":4,"id":"d3cc9588","metadata":{"execution":{"iopub.execute_input":"2025-09-19T17:44:20.57353Z","iopub.status.busy":"2025-09-19T17:44:20.573205Z","iopub.status.idle":"2025-09-19T17:44:25.728924Z","shell.execute_reply":"2025-09-19T17:44:25.728167Z"},"papermill":{"duration":5.16224,"end_time":"2025-09-19T17:44:25.731107","exception":false,"start_time":"2025-09-19T17:44:20.568867","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["IID Global Model Accuracy: 0.8537\n","Non-IID Global Model Accuracy: 0.8507\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","\n","# FedAvg aggregation function\n","def fed_avg(models, client_sizes):\n","    total_samples = sum(client_sizes)\n","    avg_coef = np.sum([model.coef_ * (n / total_samples) for model, n in zip(models, client_sizes)], axis=0)\n","    avg_intercept = np.sum([model.intercept_ * (n / total_samples) for model, n in zip(models, client_sizes)], axis=0)\n","    \n","    global_model = LogisticRegression(max_iter=1000)\n","    global_model.coef_ = avg_coef\n","    global_model.intercept_ = avg_intercept\n","    global_model.classes_ = models[0].classes_  # <-- Fix: Set classes_\n","    return global_model\n","\n","# Function to simulate one FL round\n","def train_federated(clients, rounds=3, C=1.0):\n","    global_model = LogisticRegression(max_iter=1000)\n","    \n","    for r in range(rounds):\n","        local_models = []\n","        local_sizes = []\n","        \n","        for data in clients:\n","            X = data.drop(columns=['target']).values\n","            y = data['target'].values\n","            \n","            local_model = LogisticRegression(max_iter=1000, C=C)\n","            local_model.fit(X, y)\n","            \n","            local_models.append(local_model)\n","            local_sizes.append(len(X))\n","        \n","        # Aggregate into global model\n","        global_model = fed_avg(local_models, local_sizes)\n","    \n","    return global_model\n","\n","# Train on IID and Non-IID splits\n","iid_global_model = train_federated(iid_clients)\n","non_iid_global_model = train_federated(non_iid_clients)\n","\n","# Evaluate\n","X_full = df.drop(columns=['target']).values\n","y_full = df['target'].values\n","\n","iid_acc = accuracy_score(y_full, iid_global_model.predict(X_full))\n","non_iid_acc = accuracy_score(y_full, non_iid_global_model.predict(X_full))\n","\n","print(f\"IID Global Model Accuracy: {iid_acc:.4f}\")\n","print(f\"Non-IID Global Model Accuracy: {non_iid_acc:.4f}\")\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":216167,"sourceId":477177,"sourceType":"datasetVersion"}],"dockerImageVersionId":31089,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":13.463265,"end_time":"2025-09-19T17:44:26.458769","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-09-19T17:44:12.995504","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}